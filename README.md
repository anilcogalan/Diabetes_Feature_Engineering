# Diabetes Feature Engineering
<p align="center">
<img src="https://user-images.githubusercontent.com/61653147/230106778-5039e391-ad7d-4378-9558-55332606e78d.png" width="400" height="400">
</p>

## Business Problem 

It is desired to develop a machine learning model that can predict whether people have diabetes when their characteristics are specified. You are expected to perform the necessary data analysis and feature engineering steps before developing the model.

## Data-Set

The dataset is part of the large dataset held at the National Institutes of Diabetes-Digestive-Kidney Diseases in the USA. Data used for diabetes research on Pima Indian women aged 21 and over living in Phoenix, the 5th largest city of the State of Arizona in the USA. It consists of 768 observations and 8 numerical independent variables. The target variable is specified as "outcome"; 1 indicates positive diabetes test result, 0 indicates negative.

| Columns Name | Type     | Description                |
| :-------- | :------- | :------------------------- |
| `Pregnancies:` | `int64` | Number of pregnancies  |
| `Glucose` | `int64` | Glucose   |
| `BloodPressure` | `int64` | Blood pressure (Diastolic)   |
| `SkinThickness` | `int64` | Skin Thickness   |
| `Insulin` | `int64` | Insulin |
| `BMI` | `float64` | Body mass index |
| `DiabetesPedigreeFunction` | `float64` |A function that calculates our probability of having diabetes based on our descendants. |
| `Age` | `int64` | Age (year) |
| `Outcome` | `int64` |  Information whether the person has diabetes or not. Have the disease (1) or not (0) |

## Lessons Learned

1. **Data collection:** Collect data from various sources, which could include web scraping, APIs, databases, and flat files.

2. **Data cleaning:** Clean and preprocess the data to handle missing values, outliers, duplicates, and other data quality issues.

3. **Exploratory data analysis (EDA):** Analyze and visualize the data to gain insights and understand the relationships between features.

4. **Feature selection:** Choose the most relevant features based on EDA, domain knowledge, or statistical tests.

5. **Feature scaling:** Scale the features to a common range to avoid bias towards features with larger values.

6. **Feature transformation:** Transform the features using mathematical operations like logarithmic, exponential, or power functions to create new features or improve their distribution.

7. **Feature encoding:** Encode categorical features using techniques like one-hot encoding, ordinal encoding, or target encoding to convert them into numerical values.

8. **Feature extraction:** Extract features from unstructured data like text or images using techniques like bag-of-words, TF-IDF, or CNNs.

9. **Feature generation:** Create new features using combinations of existing features or external data sources to capture higher-level relationships.

10. **Feature validation:** Validate the selected features by testing the model's performance on a validation set or using cross-validation techniques.

## ðŸ”— Links
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/)
[![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/@anilcogalan)
[![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white)](https://www.kaggle.com/anilcogalan)


